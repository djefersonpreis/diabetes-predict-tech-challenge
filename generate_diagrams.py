#!/usr/bin/env python3
"""
Script para gerar diagramas visuais da arquitetura da aplicaÃ§Ã£o
ExecuÃ§Ã£o: python generate_diagrams.py
"""

from diagrams import Diagram, Cluster, Edge
from diagrams.onprem.container import Docker
from diagrams.generic.database import SQL
from diagrams.programming.framework import Fastapi
from diagrams.programming.language import Python
from diagrams.generic.blank import Blank
from diagrams.generic.storage import Storage
from diagrams.aws.general import User
from diagrams.onprem.client import Client
import os

def create_architecture_diagram():
    """Cria diagrama da arquitetura geral do sistema"""
    
    with Diagram("ğŸ©º Arquitetura - Sistema PrediÃ§Ã£o Diabetes", 
                 filename="docs/architecture_diagram", 
                 show=False,
                 direction="TB"):
        
        # Camada de usuÃ¡rio
        user = User("ğŸ‘¤ UsuÃ¡rio")
        
        # Camada de interface
        with Cluster("ğŸŒ Interface Web"):
            dashboard = Client("ğŸ“Š Dashboard\nStreamlit:8501")
            api_docs = Client("ğŸš€ API Docs\nSwagger:8000")
        
        # Camada de aplicaÃ§Ã£o (Containers)
        with Cluster("ğŸ³ Containers Docker"):
            with Cluster("Container Dashboard"):
                streamlit_app = Python("Streamlit App")
            
            with Cluster("Container API"):
                fastapi_app = Fastapi("FastAPI App")
        
        # Camada de negÃ³cio
        with Cluster("ğŸ¤– Camada ML"):
            data_collector = Python("ğŸ“¥ Data\nCollector")
            data_processor = Python("âš™ï¸ Data\nProcessor")
            ml_model = Python("ğŸ¯ ML Model\nRandom Forest")
        
        # Camada de dados
        with Cluster("ğŸ’¾ PersistÃªncia"):
            sqlite_db = SQL("ğŸ—„ï¸ SQLite\nraw_data + processed_data")
            model_storage = Storage("ğŸ’¾ Model Files\n.joblib")
        
        # Fonte externa
        kaggle = Storage("ğŸŒ Kaggle Dataset\n250k+ registros")
        
        # ConexÃµes
        user >> dashboard
        user >> api_docs
        
        dashboard >> streamlit_app
        api_docs >> fastapi_app
        
        fastapi_app >> [data_collector, data_processor, ml_model]
        streamlit_app >> fastapi_app
        
        data_collector >> kaggle
        data_collector >> sqlite_db
        data_processor >> sqlite_db
        ml_model >> sqlite_db
        ml_model >> model_storage

def create_data_flow_diagram():
    """Cria diagrama do fluxo de dados"""
    
    with Diagram("ğŸ”„ Fluxo de Dados - Pipeline ML", 
                 filename="docs/data_flow_diagram", 
                 show=False,
                 direction="LR"):
        
        # Processo sequencial
        start = Python("ğŸš€ InÃ­cio")
        
        collect = Python("ğŸ“¥ Coleta\nKaggle API")
        process = Python("âš™ï¸ Processamento\nLimpeza + Features")
        train = Python("ğŸ¤– Treinamento\nRandom Forest")
        deploy = Python("ğŸš€ Deploy\nAPI + Dashboard")
        predict = Python("ğŸ¯ PrediÃ§Ã£o\nTempo Real")
        
        end = Python("âœ… Fim")
        
        # Base de dados
        raw_db = SQL("Raw Data")
        processed_db = SQL("Processed Data")
        model_files = Storage("Model Files")
        
        # Fluxo principal
        start >> collect >> raw_db
        raw_db >> process >> processed_db
        processed_db >> train >> model_files
        model_files >> deploy >> predict >> end

def create_container_diagram():
    """Cria diagrama dos containers Docker"""
    
    with Diagram("ğŸ³ Containers - Deployment View", 
                 filename="docs/container_diagram", 
                 show=False,
                 direction="TB"):
        
        # Docker Compose
        docker_compose = Docker("ğŸ³ Docker Compose")
        
        # Containers
        with Cluster("diabetes-api"):
            api_container = Docker("API Container\nPort 8000")
            api_app = Fastapi("FastAPI")
            api_container >> api_app
        
        with Cluster("diabetes-dashboard"):
            dash_container = Docker("Dashboard Container\nPort 8501")
            dash_app = Python("Streamlit")
            dash_container >> dash_app
        
        # Volumes compartilhados
        with Cluster("ğŸ“‚ Volumes Compartilhados"):
            data_volume = Storage("/data")
            models_volume = Storage("/models")
        
        # Rede interna
        network = Blank("ğŸŒ Docker Network\ndiabetes-network")
        
        # ConexÃµes
        docker_compose >> [api_container, dash_container]
        
        api_container >> data_volume
        api_container >> models_volume
        dash_container >> data_volume
        dash_container >> models_volume
        
        [api_container, dash_container] >> network

def create_ml_pipeline_diagram():
    """Cria diagrama especÃ­fico do pipeline de ML"""
    
    with Diagram("ğŸ¤– Pipeline Machine Learning", 
                 filename="docs/ml_pipeline_diagram", 
                 show=False,
                 direction="TB"):
        
        # Entrada
        raw_data = Storage("ğŸ“Š Dataset Bruto\n253,680 registros\n22 colunas")
        
        # Processamento
        with Cluster("âš™ï¸ Data Processing"):
            cleaning = Python("ğŸ§¹ Limpeza\nValores faltantes\nOutliers")
            feature_eng = Python("ğŸ”§ Feature Engineering\nSeleÃ§Ã£o + NormalizaÃ§Ã£o")
            validation = Python("âœ… ValidaÃ§Ã£o\nQualidade dos dados")
        
        # Dados processados
        processed_data = Storage("ğŸ“ˆ Dataset Processado\n11 features selecionadas")
        
        # Treinamento
        with Cluster("ğŸ¤– Model Training"):
            split = Python("ğŸ“Š Train/Test Split\n80/20")
            training = Python("ğŸ¯ Random Forest\n100 Ã¡rvores")
            evaluation = Python("ğŸ“ AvaliaÃ§Ã£o\nAccuracy: 87.5%")
        
        # Modelo treinado
        with Cluster("ğŸ’¾ Model Artifacts"):
            model_file = Storage("ğŸ¤– model.joblib")
            scaler_file = Storage("ğŸ“ scaler.joblib")
            features_file = Storage("ğŸ“‹ feature_names.joblib")
        
        # PrediÃ§Ã£o
        prediction = Python("ğŸ¯ PrediÃ§Ã£o\nTempo Real")
        
        # Fluxo
        raw_data >> cleaning >> feature_eng >> validation >> processed_data
        processed_data >> split >> training >> evaluation
        evaluation >> [model_file, scaler_file, features_file]
        [model_file, scaler_file, features_file] >> prediction

def create_api_endpoints_diagram():
    """Cria diagrama dos endpoints da API"""
    
    with Diagram("ğŸš€ API Endpoints - FastAPI", 
                 filename="docs/api_endpoints_diagram", 
                 show=False,
                 direction="LR"):
        
        # Cliente
        client = Client("ğŸ‘¤ Cliente\nDashboard/External")
        
        # API Gateway
        api = Fastapi("ğŸš€ FastAPI\nlocalhost:8000")
        
        # Endpoints
        with Cluster("ğŸ“¡ Endpoints"):
            health = Python("GET /health\nStatus da aplicaÃ§Ã£o")
            data_stats = Python("GET /data-stats\nEstatÃ­sticas dos dados")
            collect = Python("POST /collect-data\nColeta do Kaggle")
            process = Python("POST /process-data\nProcessamento")
            train = Python("POST /train-model\nTreinamento ML")
            model_info = Python("GET /model-info\nInfo do modelo")
            predict = Python("POST /predict\nPrediÃ§Ã£o individual")
        
        # ServiÃ§os
        with Cluster("ğŸ› ï¸ Services"):
            data_service = Python("DataService")
            ml_service = Python("MLService")
            db_service = SQL("DatabaseService")
        
        # ConexÃµes
        client >> api
        api >> [health, data_stats, collect, process, train, model_info, predict]
        
        [collect, process] >> data_service
        [train, model_info, predict] >> ml_service
        data_service >> db_service
        ml_service >> db_service

def main():
    """FunÃ§Ã£o principal que gera todos os diagramas"""
    
    print("ğŸ¨ Gerando diagramas da arquitetura...")
    
    # Criar diretÃ³rio se nÃ£o existir
    os.makedirs("docs", exist_ok=True)
    
    # Gerar diagramas
    print("  ğŸ“Š Diagrama de arquitetura geral...")
    create_architecture_diagram()
    
    print("  ğŸ”„ Diagrama de fluxo de dados...")
    create_data_flow_diagram()
    
    print("  ğŸ³ Diagrama de containers...")
    create_container_diagram()
    
    print("  ğŸ¤– Diagrama do pipeline ML...")
    create_ml_pipeline_diagram()
    
    print("  ğŸš€ Diagrama dos endpoints API...")
    create_api_endpoints_diagram()
    
    print("âœ… Diagramas gerados com sucesso em /docs/")
    print("\nğŸ“ Arquivos criados:")
    print("  - architecture_diagram.png")
    print("  - data_flow_diagram.png") 
    print("  - container_diagram.png")
    print("  - ml_pipeline_diagram.png")
    print("  - api_endpoints_diagram.png")
    
    print("\nğŸ’¡ Para visualizar:")
    print("  - Abra os arquivos .png no /docs/")
    print("  - Ou use: display docs/*.png (Linux)")
    print("  - Ou use: open docs/*.png (macOS)")

if __name__ == "__main__":
    main()